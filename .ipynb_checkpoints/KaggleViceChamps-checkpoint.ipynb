{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter sentiment presented by @Radras and @sekularacn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import html\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset loading function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path_to_file):\n",
    "    X, y = [], []\n",
    "    with codecs.open(path_to_file, \"r\",encoding='utf-8', errors='ignore') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "        next(reader, None) # Skip header\n",
    "        for row in reader:\n",
    "            y.append(int(row[1]))\n",
    "            X.append(row[2])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of data: 99989  Len of labels: 99989\n"
     ]
    }
   ],
   "source": [
    "x_data, y_data = load_dataset('data/train.csv')\n",
    "\n",
    "print('Len of data:', len(x_data), ' Len of labels:', len(y_data))\n",
    "\n",
    "# Getting the random data from the dataset.\n",
    "# \n",
    "indices = np.random.choice(range(99989), 10000, replace=False)\n",
    "\n",
    "X_random_data = [x_data[i] for i in indices]\n",
    "y_random_labels = [y_data[i] for i in indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "\n",
    "- Deleting mentions\n",
    "- Deleting links\n",
    "- Fixing the HTML symbols for unicode chars\n",
    "- Removing punctation\n",
    "- Lowercasing all\n",
    "- Removing all the numeric values\n",
    "- Removing stopwords\n",
    "- Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting links. Tokenizers don't work.\n",
    "for i in range(len(X_random_data)):\n",
    "    sentence = X_random_data[i].split(' ')\n",
    "    new_sentence = []\n",
    "    for word in sentence:\n",
    "        if word[:4] != 'http':\n",
    "            new_sentence.append(word)\n",
    "    X_random_data[i] = ' '.join(new_sentence)\n",
    "\n",
    "for i in range(len(X_random_data)):\n",
    "    # Removing twitter mentions\n",
    "    X_random_data[i] = re.sub(r'@\\w+', \"\", X_random_data[i])\n",
    "    \n",
    "    # Removing HTML escaped symbols\n",
    "    X_random_data[i] = html.unescape(X_random_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n",
      "[['looking', 'at', 'apartments', 'in', 'la', 'and', 'i', 'just', 'found', 'a', 'reallyy', 'nice', 'one'], ['danna', 'pe単a', \"i've\", 'been', 'with', 'you', 'for', 'two', 'years', 'what', 'will', 'i', 'do', 'without', 'you', 'threesome', 'aint', 'complete', 'either', 'oh', 'life', \"i'm\", 'c', 'btw'], ['lol', 'all', 'i', 'seen', 'was', 'my', 'baby', 'peanut'], [\"don't\", 'worry', 'god', 'has', 'the', 'perfect', 'man', 'for', 'you'], ['hmm', 'are', 'you', 'sure', 'think', 'u', 'were', 'a', 'bit', 'quick', 'to', 'deny', 'it']]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, regexp_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from data.utils import correct_spelling, remove_more_than_two_duplicate_letters\n",
    "\n",
    "# forms list of sentences per every tweet\n",
    "all_words = [regexp_tokenize(sample, \"[\\w']+\") for sample in X_random_data]\n",
    "\n",
    "# removes words with more than 2 same chars, and converts to lowercase\n",
    "for i in range(len(all_words)):\n",
    "    for j in range(len(all_words[i])):\n",
    "        all_words[i][j] = remove_more_than_two_duplicate_letters(all_words[i][j].lower())\n",
    "print(\"finished\")\n",
    "\n",
    "print(all_words[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning numbers and stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correction_dicts():\n",
    "\t'''\tLoads 3 dictionaries with the correct substitions\n",
    "\t\tfor words. Most common mistakes while tweeting.\n",
    "\t'''\n",
    "\twords = {}\n",
    "\t# Dict1 structure: number wrong_typed_word | corrected_word\n",
    "\n",
    "\twith open('data/dict1.txt', 'rb') as word_file:\n",
    "\t\tfor word in word_file:\n",
    "\t\t\tword = word.decode('utf-8').split()\n",
    "\t\t\twords[word[1]] = word[3]\n",
    "\n",
    "\t# Dict2 structure: wrong_word corrected_word\n",
    "\twith open('data/dict2.txt', 'rb') as word_file:\n",
    "\t\tfor word in word_file:\n",
    "\t\t\tword = word.decode('utf-8').split()\n",
    "\t\t\twords[word[0]] = word[1]\n",
    "\n",
    "\t# Dict3 structure: wrong_word corrected_word\n",
    "\twith open('data/dict3.txt', 'rb') as word_file:\n",
    "\t\tfor word in word_file:\n",
    "\t\t\tword = word.decode('utf-8').split()\n",
    "\t\t\twords[word[0]] = word[1]\n",
    "\n",
    "\treturn words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_dictionary = {}\n",
    "words_dictionary = get_correction_dicts()\n",
    "\n",
    "# clean the set from the numeric values and remove stopwords\n",
    "for i in range(len(all_words)):\n",
    "    all_words[i] = [word for word in all_words[i] if not word.isnumeric()]\n",
    "    all_words[i] = [word for word in all_words[i] if word not in stopwords.words('english')]\n",
    "    all_words[i] = correct_spelling(all_words[i], words_dictionary)\n",
    "    all_words[i] = [word for word in all_words[i] if len(word) > 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['looking', 'apartments', 'la', 'found', 'really', 'nice', 'one']\n",
      "['anna', 'pe単a', \"i've\", 'two', 'years', 'without', 'threesome', 'aint', 'complete', 'either', 'oh', 'life', \"i'm\", 'see', 'btw']\n",
      "['lot', 'seen', 'baby', 'peanut']\n",
      "['worry', 'god', 'perfect', 'man']\n",
      "['him', 'sure', 'think', 'you', 'bit', 'quick', 'deny']\n",
      "['thanks', 'mac']\n",
      "['symptoms', 'thyphoid', 'fever', 'includes', 'malaise', 'anorexia', 'abdominal', 'pain', 'fever', 'insomnia', 'oh', 'boy']\n",
      "['lololol', 'telling', 'eisu', \"chul's\", 'chuck', 'norris', 'oots', 'verse', 'clearly', 'like', 'explanation', 'better']\n",
      "['him', \"i'll\", 'think', 'know', 'vocal', 'siamese', 'may', 'give', 'little', 'us', 'one', 'authorities']\n",
      "['ictev09', 'getting', 'ready', 'man', 'give', 'talk', 'school', 'it', 'changes', 'asked', 'help', 'another', 'session', 'afterward']\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(all_words[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "Using PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['look', 'apart', 'la', 'found', 'realli', 'nice', 'one']\n",
      "['anna', 'pe単a', \"i'v\", 'two', 'year', 'without', 'threesom', 'aint', 'complet', 'either', 'oh', 'life', \"i'm\", 'see', 'btw']\n",
      "['lot', 'seen', 'babi', 'peanut']\n",
      "['worri', 'god', 'perfect', 'man']\n",
      "['him', 'sure', 'think', 'you', 'bit', 'quick', 'deni']\n",
      "['thank', 'mac']\n",
      "['symptom', 'thyphoid', 'fever', 'includ', 'malais', 'anorexia', 'abdomin', 'pain', 'fever', 'insomnia', 'oh', 'boy']\n",
      "['lololol', 'tell', 'eisu', \"chul'\", 'chuck', 'norri', 'oot', 'vers', 'clearli', 'like', 'explan', 'better']\n",
      "['him', \"i'll\", 'think', 'know', 'vocal', 'siames', 'may', 'give', 'littl', 'us', 'one', 'author']\n",
      "['ictev09', 'get', 'readi', 'man', 'give', 'talk', 'school', 'it', 'chang', 'ask', 'help', 'anoth', 'session', 'afterward']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "for i in range(len(all_words)):\n",
    "    for j in range(len(all_words[i])):\n",
    "        all_words[i][j] = porter.stem(all_words[i][j])\n",
    "        \n",
    "for i in range(10):\n",
    "    print(all_words[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['look apart la found realli nice one', \"anna pe単a i'v two year without threesom aint complet either oh life i'm see btw\", 'lot seen babi peanut', 'worri god perfect man', 'him sure think you bit quick deni']\n"
     ]
    }
   ],
   "source": [
    "# Repositioning the sentences\n",
    "\n",
    "clean_sentences = []\n",
    "for lista in all_words:\n",
    "    clean_sentences.append(\" \".join(lista))\n",
    "\n",
    "print(clean_sentences[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Bag of Words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000) \n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "train_data_features = vectorizer.fit_transform(clean_sentences)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an \n",
    "# array\n",
    "train_data_features = train_data_features.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.65\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data_features, y_random_labels, test_size=0.2, random_state=23)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_diff = y_pred == y_test\n",
    "\n",
    "cnt = 0\n",
    "for b in y_diff:\n",
    "    if b:\n",
    "        cnt += 1\n",
    "print((cnt / len(y_diff)) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.651\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=101)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_diff = y_pred == y_test\n",
    "\n",
    "cnt = 0\n",
    "for qwe in y_diff:\n",
    "    if qwe:\n",
    "        cnt += 1\n",
    "print(cnt/len(y_diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing dataset into train, val and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: 5000\n",
      "X_validate shape: 2500\n",
      "X_test shape: 2500\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data_features, np.array(y_random_labels), test_size=0.5, random_state=23)\n",
    "\n",
    "X_test, X_validate, y_test, y_validate = train_test_split(X_test, y_test, test_size=0.5, random_state=23)\n",
    "\n",
    "print('X_train shape:', len(X_train))\n",
    "print('X_validate shape:', len(X_validate))\n",
    "print('X_test shape:', len(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameters\n",
    "LEARNING_RATE = 0.7\n",
    "TRAINING_EPOCHS = 7000\n",
    "REGULARIZATION_PARAM = tf.constant(0.001)\n",
    "# CRITICAL::: X_TRAIN[0] MUST EXIST FOR THIS TO WORK PROPERLY\n",
    "N_FEATURES = len(X_train[0])\n",
    "\n",
    "y_train = y_train.reshape(len(y_train), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, N_FEATURES], name=\"X\")\n",
    "y = tf.placeholder(tf.float32, [None, 1], name=\"y\")\n",
    "\n",
    "Weights = tf.Variable(tf.random_normal([N_FEATURES, 1]), name=\"Weights\")\n",
    "bias = tf.Variable(tf.random_normal([1, 1]), name=\"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "hypotesis = tf.sigmoid(bias + tf.matmul(X, Weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function & L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost function\n",
    "# cost = tf.reduce_mean(-tf.multiply(y, tf.log(hypotesis)) - \n",
    "#                      tf.multiply(tf.subtract(1.0, y), tf.log(tf.subtract(1.0, hypotesis)))) \\\n",
    "#                    + tf.multiply(REGULARIZATION_PARAM, tf.matmul(tf.transpose(Weights), Weights))\n",
    "\n",
    "cost = tf.reduce_mean(tf.reduce_mean(-tf.multiply(y, tf.log(hypotesis)) - \n",
    "                      tf.multiply(tf.subtract(1.0, y), tf.log(tf.subtract(1.0, hypotesis)))) \\\n",
    "                    + tf.multiply(REGULARIZATION_PARAM, tf.nn.l2_loss(Weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_points_err = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 0, Error: 3.690992832183838, Diff of last 2: 4996.309007167816]\n",
      "[Epoch: 50, Error: 3.296319007873535, Diff of last 2: 0.005610942840576172]\n",
      "[Epoch: 100, Error: 3.0374677181243896, Diff of last 2: 0.004803180694580078]\n",
      "[Epoch: 150, Error: 2.813596248626709, Diff of last 2: 0.004190683364868164]\n",
      "[Epoch: 200, Error: 2.6166908740997314, Diff of last 2: 0.0037107467651367188]\n",
      "[Epoch: 250, Error: 2.441372871398926, Diff of last 2: 0.003322124481201172]\n",
      "[Epoch: 300, Error: 2.2838826179504395, Diff of last 2: 0.002994537353515625]\n",
      "[Epoch: 350, Error: 2.1414952278137207, Diff of last 2: 0.0027132034301757812]\n",
      "[Epoch: 400, Error: 2.012166738510132, Diff of last 2: 0.0024688243865966797]\n",
      "[Epoch: 450, Error: 1.8943052291870117, Diff of last 2: 0.002252936363220215]\n",
      "[Epoch: 500, Error: 1.786623239517212, Diff of last 2: 0.002061128616333008]\n",
      "[Epoch: 550, Error: 1.6880545616149902, Diff of last 2: 0.001887679100036621]\n",
      "[Epoch: 600, Error: 1.5976895093917847, Diff of last 2: 0.00173187255859375]\n",
      "[Epoch: 650, Error: 1.5147433280944824, Diff of last 2: 0.0015912055969238281]\n",
      "[Epoch: 700, Error: 1.4385311603546143, Diff of last 2: 0.0014623403549194336]\n",
      "[Epoch: 750, Error: 1.3684446811676025, Diff of last 2: 0.0013450384140014648]\n",
      "[Epoch: 800, Error: 1.303943395614624, Diff of last 2: 0.001238703727722168]\n",
      "[Epoch: 850, Error: 1.2445454597473145, Diff of last 2: 0.0011410713195800781]\n",
      "[Epoch: 900, Error: 1.1898168325424194, Diff of last 2: 0.001051783561706543]\n",
      "[Epoch: 950, Error: 1.1393654346466064, Diff of last 2: 0.0009692907333374023]\n",
      "[Epoch: 1000, Error: 1.0928354263305664, Diff of last 2: 0.0008943080902099609]\n",
      "[Epoch: 1050, Error: 1.0499064922332764, Diff of last 2: 0.0008246898651123047]\n",
      "[Epoch: 1100, Error: 1.0102853775024414, Diff of last 2: 0.0007621049880981445]\n",
      "[Epoch: 1150, Error: 0.9737052917480469, Diff of last 2: 0.0007035136222839355]\n",
      "[Epoch: 1200, Error: 0.9399233460426331, Diff of last 2: 0.0006492137908935547]\n",
      "[Epoch: 1250, Error: 0.9087151885032654, Diff of last 2: 0.0006003379821777344]\n",
      "[Epoch: 1300, Error: 0.8798779249191284, Diff of last 2: 0.0005546808242797852]\n",
      "[Epoch: 1350, Error: 0.8532246351242065, Diff of last 2: 0.0005125999450683594]\n",
      "[Epoch: 1400, Error: 0.8285830020904541, Diff of last 2: 0.0004743337631225586]\n",
      "[Epoch: 1450, Error: 0.8057972192764282, Diff of last 2: 0.0004385709762573242]\n",
      "[Epoch: 1500, Error: 0.784721851348877, Diff of last 2: 0.00040543079376220703]\n",
      "[Epoch: 1550, Error: 0.765224814414978, Diff of last 2: 0.0003751516342163086]\n",
      "[Epoch: 1600, Error: 0.7471835613250732, Diff of last 2: 0.0003472566604614258]\n",
      "[Epoch: 1650, Error: 0.7304873466491699, Diff of last 2: 0.00032132863998413086]\n",
      "[Epoch: 1700, Error: 0.7150317430496216, Diff of last 2: 0.00029736757278442383]\n",
      "[Epoch: 1750, Error: 0.7007230520248413, Diff of last 2: 0.00027549266815185547]\n",
      "[Epoch: 1800, Error: 0.6874735355377197, Diff of last 2: 0.0002551078796386719]\n",
      "[Epoch: 1850, Error: 0.6752030849456787, Diff of last 2: 0.00023615360260009766]\n",
      "[Epoch: 1900, Error: 0.6638369560241699, Diff of last 2: 0.00021857023239135742]\n",
      "[Epoch: 1950, Error: 0.6533075571060181, Diff of last 2: 0.00020253658294677734]\n",
      "[Epoch: 2000, Error: 0.6435511112213135, Diff of last 2: 0.00018793344497680664]\n",
      "[Epoch: 2050, Error: 0.6345107555389404, Diff of last 2: 0.0001741647720336914]\n",
      "[Epoch: 2100, Error: 0.6261321306228638, Diff of last 2: 0.00016170740127563477]\n",
      "[Epoch: 2150, Error: 0.6183656454086304, Diff of last 2: 0.00014978647232055664]\n",
      "[Epoch: 2200, Error: 0.6111664175987244, Diff of last 2: 0.00013887882232666016]\n",
      "[Epoch: 2250, Error: 0.6044912338256836, Diff of last 2: 0.0001289844512939453]\n",
      "[Epoch: 2300, Error: 0.5983025431632996, Diff of last 2: 0.00011903047561645508]\n",
      "[Epoch: 2350, Error: 0.5925629138946533, Diff of last 2: 0.000110626220703125]\n",
      "[Epoch: 2400, Error: 0.5872402191162109, Diff of last 2: 0.00010222196578979492]\n",
      "[Epoch: 2450, Error: 0.5823029279708862, Diff of last 2: 9.512901306152344e-05]\n",
      "[Epoch: 2500, Error: 0.5777233242988586, Diff of last 2: 8.815526962280273e-05]\n",
      "[Epoch: 2550, Error: 0.5734742879867554, Diff of last 2: 8.225440979003906e-05]\n",
      "[Epoch: 2600, Error: 0.5695326328277588, Diff of last 2: 7.599592208862305e-05]\n",
      "[Epoch: 2650, Error: 0.5658751130104065, Diff of last 2: 7.039308547973633e-05]\n",
      "[Epoch: 2700, Error: 0.5624809861183167, Diff of last 2: 6.54458999633789e-05]\n",
      "[Epoch: 2750, Error: 0.5593315362930298, Diff of last 2: 6.085634231567383e-05]\n",
      "[Epoch: 2800, Error: 0.5564081072807312, Diff of last 2: 5.632638931274414e-05]\n",
      "[Epoch: 2850, Error: 0.5536948442459106, Diff of last 2: 5.21540641784668e-05]\n",
      "[Epoch: 2900, Error: 0.5511762499809265, Diff of last 2: 4.857778549194336e-05]\n",
      "[Epoch: 2950, Error: 0.5488384366035461, Diff of last 2: 4.494190216064453e-05]\n",
      "[Epoch: 3000, Error: 0.5466678142547607, Diff of last 2: 4.172325134277344e-05]\n",
      "[Epoch: 3050, Error: 0.5446523427963257, Diff of last 2: 3.921985626220703e-05]\n",
      "[Epoch: 3100, Error: 0.5427815318107605, Diff of last 2: 3.618001937866211e-05]\n",
      "[Epoch: 3150, Error: 0.5410441756248474, Diff of last 2: 3.331899642944336e-05]\n",
      "[Epoch: 3200, Error: 0.5394307374954224, Diff of last 2: 3.0994415283203125e-05]\n",
      "[Epoch: 3250, Error: 0.5379323959350586, Diff of last 2: 2.872943878173828e-05]\n",
      "[Epoch: 3300, Error: 0.5365407466888428, Diff of last 2: 2.682209014892578e-05]\n",
      "[Epoch: 3350, Error: 0.5352482199668884, Diff of last 2: 2.4974346160888672e-05]\n",
      "[Epoch: 3400, Error: 0.5340479016304016, Diff of last 2: 2.3245811462402344e-05]\n",
      "[Epoch: 3450, Error: 0.5329325795173645, Diff of last 2: 2.1696090698242188e-05]\n",
      "[Epoch: 3500, Error: 0.5318971872329712, Diff of last 2: 1.9788742065429688e-05]\n",
      "[Epoch: 3550, Error: 0.5309345722198486, Diff of last 2: 1.8894672393798828e-05]\n",
      "[Epoch: 3600, Error: 0.5300410389900208, Diff of last 2: 1.6927719116210938e-05]\n",
      "[Epoch: 3650, Error: 0.5292102098464966, Diff of last 2: 1.621246337890625e-05]\n",
      "[Epoch: 3700, Error: 0.5284385681152344, Diff of last 2: 1.4960765838623047e-05]\n",
      "[Epoch: 3750, Error: 0.5277215838432312, Diff of last 2: 1.3828277587890625e-05]\n",
      "[Epoch: 3800, Error: 0.5270551443099976, Diff of last 2: 1.3232231140136719e-05]\n",
      "[Epoch: 3850, Error: 0.5264360308647156, Diff of last 2: 1.1861324310302734e-05]\n",
      "[Epoch: 3900, Error: 0.525860607624054, Diff of last 2: 1.1205673217773438e-05]\n",
      "[Epoch: 3950, Error: 0.525326132774353, Diff of last 2: 1.049041748046875e-05]\n",
      "[Epoch: 4000, Error: 0.5248293280601501, Diff of last 2: 9.417533874511719e-06]\n",
      "[Epoch: 4050, Error: 0.5243673920631409, Diff of last 2: 9.000301361083984e-06]\n",
      "[Epoch: 4100, Error: 0.5239380598068237, Diff of last 2: 8.404254913330078e-06]\n",
      "[Epoch: 4150, Error: 0.5235391855239868, Diff of last 2: 7.748603820800781e-06]\n",
      "[Epoch: 4200, Error: 0.5231682062149048, Diff of last 2: 7.331371307373047e-06]\n",
      "[Epoch: 4250, Error: 0.5228235721588135, Diff of last 2: 6.794929504394531e-06]\n",
      "[Epoch: 4300, Error: 0.5225032567977905, Diff of last 2: 6.020069122314453e-06]\n",
      "[Epoch: 4350, Error: 0.5222052335739136, Diff of last 2: 5.662441253662109e-06]\n",
      "[Epoch: 4400, Error: 0.521928608417511, Diff of last 2: 5.304813385009766e-06]\n",
      "[Epoch: 4450, Error: 0.5216709971427917, Diff of last 2: 4.887580871582031e-06]\n",
      "[Epoch: 4500, Error: 0.5214316844940186, Diff of last 2: 4.291534423828125e-06]\n",
      "[Epoch: 4550, Error: 0.5212088823318481, Diff of last 2: 4.291534423828125e-06]\n",
      "[Epoch: 4600, Error: 0.5210021734237671, Diff of last 2: 3.993511199951172e-06]\n",
      "[Epoch: 4650, Error: 0.5208098292350769, Diff of last 2: 3.4570693969726562e-06]\n",
      "[Epoch: 4700, Error: 0.520630955696106, Diff of last 2: 3.337860107421875e-06]\n",
      "[Epoch: 4750, Error: 0.5204646587371826, Diff of last 2: 3.337860107421875e-06]\n",
      "[Epoch: 4800, Error: 0.5203100442886353, Diff of last 2: 2.86102294921875e-06]\n",
      "[Epoch: 4850, Error: 0.5201659202575684, Diff of last 2: 2.9802322387695312e-06]\n",
      "[Epoch: 4900, Error: 0.5200322270393372, Diff of last 2: 2.7418136596679688e-06]\n",
      "[Epoch: 4950, Error: 0.5199081897735596, Diff of last 2: 2.384185791015625e-06]\n",
      "[Epoch: 5000, Error: 0.5197925567626953, Diff of last 2: 2.0265579223632812e-06]\n",
      "[Epoch: 5050, Error: 0.519684910774231, Diff of last 2: 1.9669532775878906e-06]\n",
      "[Epoch: 5100, Error: 0.5195849537849426, Diff of last 2: 1.9073486328125e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 5150, Error: 0.51949143409729, Diff of last 2: 2.0265579223632812e-06]\n",
      "[Epoch: 5200, Error: 0.5194051861763, Diff of last 2: 1.6093254089355469e-06]\n",
      "[Epoch: 5250, Error: 0.5193250775337219, Diff of last 2: 1.3113021850585938e-06]\n",
      "[Epoch: 5300, Error: 0.5192498564720154, Diff of last 2: 1.4901161193847656e-06]\n",
      "[Epoch: 5350, Error: 0.5191802382469177, Diff of last 2: 1.3709068298339844e-06]\n",
      "[Epoch: 5400, Error: 0.5191155672073364, Diff of last 2: 1.3709068298339844e-06]\n",
      "[Epoch: 5450, Error: 0.5190552473068237, Diff of last 2: 1.0132789611816406e-06]\n",
      "[Epoch: 5500, Error: 0.5189992189407349, Diff of last 2: 1.1920928955078125e-06]\n",
      "[Epoch: 5550, Error: 0.5189469456672668, Diff of last 2: 9.5367431640625e-07]\n",
      "[Epoch: 5600, Error: 0.518898606300354, Diff of last 2: 8.344650268554688e-07]\n",
      "[Epoch: 5650, Error: 0.518853485584259, Diff of last 2: 8.940696716308594e-07]\n",
      "[Epoch: 5700, Error: 0.5188114643096924, Diff of last 2: 8.344650268554688e-07]\n",
      "[Epoch: 5750, Error: 0.5187724828720093, Diff of last 2: 7.152557373046875e-07]\n",
      "[Epoch: 5800, Error: 0.5187360644340515, Diff of last 2: 5.960464477539062e-07]\n",
      "[Epoch: 5850, Error: 0.5187023878097534, Diff of last 2: 7.152557373046875e-07]\n",
      "[Epoch: 5900, Error: 0.5186710953712463, Diff of last 2: 5.364418029785156e-07]\n",
      "[Epoch: 5950, Error: 0.5186415910720825, Diff of last 2: 7.152557373046875e-07]\n",
      "[Epoch: 6000, Error: 0.5186147093772888, Diff of last 2: 5.364418029785156e-07]\n",
      "[Epoch: 6050, Error: 0.5185893774032593, Diff of last 2: 3.5762786865234375e-07]\n",
      "[Epoch: 6100, Error: 0.5185657143592834, Diff of last 2: 4.76837158203125e-07]\n",
      "[Epoch: 6150, Error: 0.5185437798500061, Diff of last 2: 4.76837158203125e-07]\n",
      "[Epoch: 6200, Error: 0.5185232162475586, Diff of last 2: 2.384185791015625e-07]\n",
      "[Epoch: 6250, Error: 0.5185044407844543, Diff of last 2: 4.76837158203125e-07]\n",
      "[Epoch: 6300, Error: 0.518486738204956, Diff of last 2: 3.5762786865234375e-07]\n",
      "[Epoch: 6350, Error: 0.5184704661369324, Diff of last 2: 2.384185791015625e-07]\n",
      "[Epoch: 6400, Error: 0.5184550881385803, Diff of last 2: 3.5762786865234375e-07]\n",
      "[Epoch: 6450, Error: 0.5184410810470581, Diff of last 2: 4.172325134277344e-07]\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    epsylon = 0.0000001\n",
    "    last_err = 5000\n",
    "    for epoch in range(TRAINING_EPOCHS):\n",
    "        _, err = sess.run([train_op, cost], {X: X_train, y: y_train})\n",
    "        plotting_points_err.append(err)\n",
    "        if abs(last_err - err) < epsylon:\n",
    "            break\n",
    "        if epoch % 50 == 0:\n",
    "            print('[Epoch: {}, Error: {}, Diff of last 2: {}]'.format(\n",
    "                epoch, err, last_err - err\n",
    "            ))\n",
    "        last_err = err\n",
    "    W_computed, b_computed = sess.run([Weights, bias])\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYGZmnRwKZmbWyaFgZmadHApmZtbp/wO0Zk69FPIznQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a18449d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(plotting_points_err)), plotting_points_err)\n",
    "plt.ylabel('Error rate')\n",
    "plt.xlabel('# of iterations')\n",
    "plt.title(\"Error rate over time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting and testing for accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.72 %\n"
     ]
    }
   ],
   "source": [
    "#hypotesis = tf.sigmoid(bias + tf.matmul(X, Weights))\n",
    "h = tf.sigmoid(b_computed + tf.matmul(X, W_computed))\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    y_predict = sess.run(h, {X: X_validate})\n",
    "    y_predict_predict = []\n",
    "    \n",
    "    for value in y_predict:\n",
    "        if np.mean(value) >= 0.5:\n",
    "            y_predict_predict.append(1)\n",
    "        else:\n",
    "            y_predict_predict.append(0)\n",
    "    \n",
    "    y_diff = y_predict_predict == y_validate\n",
    "    \n",
    "    for value in y_diff:\n",
    "        if value:\n",
    "            cnt += 1\n",
    "    \n",
    "    print('Accuracy:', cnt/(len(y_diff)) * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_parameters(TRAINING_EPOCHS, LEARNING_RATE, cost_f, training_op, X_train, y_train):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        epsylon = 0.0000001\n",
    "        last_err = 5000\n",
    "        for epoch in range(TRAINING_EPOCHS):\n",
    "            _, err = sess.run([train_op, cost], {X: X_train, y: y_train})\n",
    "            if err == np.inf or np.isnan(err):\n",
    "                print('Inf, error, canceling')\n",
    "                return np.inf, np.inf\n",
    "            if abs(last_err - err) < epsylon:\n",
    "                break\n",
    "            if epoch % 200 == 0:\n",
    "                print('[Epoch: {}, Error: {}, Diff of last 2: {}]'.format(\n",
    "                    epoch, err, last_err - err\n",
    "                ))\n",
    "            last_err = err\n",
    "        W_computed, b_computed = sess.run([Weights, bias])\n",
    "    return W_computed, b_computed\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing the parameters to find the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_EPOCHS = 8000\n",
    "\n",
    "REG_PARAMS = [0.01, 0.01, 0.001, 0.001, 0.001, 0.0001]\n",
    "LR_PARAMS = [0.6, 0.9, 0.7, 0.5, 0.6, 0.8]\n",
    "NUMBER_OF_MODELS = 6\n",
    "\n",
    "WEIGHTS_COMPUTED = []\n",
    "BIASES_COMPUTED = []\n",
    "ACCURACIES = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: 0\n",
      "LR: 0.6\n",
      "RP: 0.01\n",
      "[Epoch: 0, Error: 25.367307662963867, Diff of last 2: 4974.632692337036]\n",
      "[Epoch: 200, Error: 2.747584819793701, Diff of last 2: 0.026213407516479492]\n",
      "[Epoch: 400, Error: 0.8085154294967651, Diff of last 2: 0.002250194549560547]\n",
      "[Epoch: 600, Error: 0.6416798830032349, Diff of last 2: 0.00019478797912597656]\n",
      "[Epoch: 800, Error: 0.6271997690200806, Diff of last 2: 1.6808509826660156e-05]\n",
      "[Epoch: 1000, Error: 0.6259346604347229, Diff of last 2: 1.7285346984863281e-06]\n",
      "MODEL: 1\n",
      "LR: 0.9\n",
      "RP: 0.01\n",
      "Inf, error, canceling\n",
      "MODEL: 2\n",
      "LR: 0.7\n",
      "RP: 0.001\n",
      "[Epoch: 0, Error: 3.704946517944336, Diff of last 2: 4996.295053482056]\n",
      "[Epoch: 200, Error: 2.5965912342071533, Diff of last 2: 0.003725767135620117]\n",
      "[Epoch: 400, Error: 1.9922232627868652, Diff of last 2: 0.002458333969116211]\n",
      "[Epoch: 600, Error: 1.580902338027954, Diff of last 2: 0.0017135143280029297]\n",
      "[Epoch: 800, Error: 1.2907965183258057, Diff of last 2: 0.0012214183807373047]\n",
      "[Epoch: 1000, Error: 1.0829530954360962, Diff of last 2: 0.0008795261383056641]\n",
      "[Epoch: 1200, Error: 0.9326491355895996, Diff of last 2: 0.0006382465362548828]\n",
      "[Epoch: 1400, Error: 0.8232894539833069, Diff of last 2: 0.00046557188034057617]\n",
      "[Epoch: 1600, Error: 0.743360161781311, Diff of last 2: 0.0003412961959838867]\n",
      "[Epoch: 1800, Error: 0.6847285628318787, Diff of last 2: 0.00025075674057006836]\n",
      "[Epoch: 2000, Error: 0.6415891647338867, Diff of last 2: 0.00018483400344848633]\n",
      "[Epoch: 2200, Error: 0.609768271446228, Diff of last 2: 0.0001361370086669922]\n",
      "[Epoch: 2400, Error: 0.5862457752227783, Diff of last 2: 0.00010061264038085938]\n",
      "[Epoch: 2600, Error: 0.5688266158103943, Diff of last 2: 7.480382919311523e-05]\n",
      "[Epoch: 2800, Error: 0.5559074878692627, Diff of last 2: 5.53131103515625e-05]\n",
      "[Epoch: 3000, Error: 0.5463134050369263, Diff of last 2: 4.088878631591797e-05]\n",
      "[Epoch: 3200, Error: 0.539179801940918, Diff of last 2: 3.081560134887695e-05]\n",
      "[Epoch: 3400, Error: 0.5338706970214844, Diff of last 2: 2.3066997528076172e-05]\n",
      "[Epoch: 3600, Error: 0.5299160480499268, Diff of last 2: 1.6868114471435547e-05]\n",
      "[Epoch: 3800, Error: 0.5269675850868225, Diff of last 2: 1.2636184692382812e-05]\n",
      "[Epoch: 4000, Error: 0.5247676968574524, Diff of last 2: 9.5367431640625e-06]\n",
      "[Epoch: 4200, Error: 0.5231252908706665, Diff of last 2: 7.3909759521484375e-06]\n",
      "[Epoch: 4400, Error: 0.5218983292579651, Diff of last 2: 5.304813385009766e-06]\n",
      "[Epoch: 4600, Error: 0.5209811925888062, Diff of last 2: 3.933906555175781e-06]\n",
      "[Epoch: 4800, Error: 0.5202953815460205, Diff of last 2: 2.9802322387695312e-06]\n",
      "[Epoch: 5000, Error: 0.519782304763794, Diff of last 2: 2.384185791015625e-06]\n",
      "[Epoch: 5200, Error: 0.5193982720375061, Diff of last 2: 1.7881393432617188e-06]\n",
      "[Epoch: 5400, Error: 0.519110918045044, Diff of last 2: 1.2516975402832031e-06]\n",
      "[Epoch: 5600, Error: 0.5188952684402466, Diff of last 2: 1.2516975402832031e-06]\n",
      "[Epoch: 5800, Error: 0.5187340974807739, Diff of last 2: 7.748603820800781e-07]\n",
      "[Epoch: 6000, Error: 0.5186132788658142, Diff of last 2: 5.364418029785156e-07]\n",
      "[Epoch: 6200, Error: 0.518522322177887, Diff of last 2: 5.364418029785156e-07]\n",
      "[Epoch: 6400, Error: 0.5184544920921326, Diff of last 2: 4.172325134277344e-07]\n",
      "MODEL: 3\n",
      "LR: 0.5\n",
      "RP: 0.001\n",
      "[Epoch: 0, Error: 3.789203643798828, Diff of last 2: 4996.210796356201]\n",
      "[Epoch: 200, Error: 2.891087770462036, Diff of last 2: 0.0033104419708251953]\n",
      "[Epoch: 400, Error: 2.3475887775421143, Diff of last 2: 0.0022602081298828125]\n",
      "[Epoch: 600, Error: 1.957370638847351, Diff of last 2: 0.0016887187957763672]\n",
      "[Epoch: 800, Error: 1.6603538990020752, Diff of last 2: 0.00130462646484375]\n",
      "[Epoch: 1000, Error: 1.4289087057113647, Diff of last 2: 0.001024007797241211]\n",
      "[Epoch: 1200, Error: 1.2465479373931885, Diff of last 2: 0.0008099079132080078]\n",
      "[Epoch: 1400, Error: 1.1019670963287354, Diff of last 2: 0.0006434917449951172]\n",
      "[Epoch: 1600, Error: 0.9868808388710022, Diff of last 2: 0.000512540340423584]\n",
      "[Epoch: 1800, Error: 0.8950110673904419, Diff of last 2: 0.0004100799560546875]\n",
      "[Epoch: 2000, Error: 0.8215130567550659, Diff of last 2: 0.00032830238342285156]\n",
      "[Epoch: 2200, Error: 0.762606680393219, Diff of last 2: 0.00026351213455200195]\n",
      "[Epoch: 2400, Error: 0.7153237462043762, Diff of last 2: 0.00021153688430786133]\n",
      "[Epoch: 2600, Error: 0.6773195266723633, Diff of last 2: 0.0001704096794128418]\n",
      "[Epoch: 2800, Error: 0.6467384696006775, Diff of last 2: 0.00013691186904907227]\n",
      "[Epoch: 3000, Error: 0.6221051812171936, Diff of last 2: 0.00011050701141357422]\n",
      "[Epoch: 3200, Error: 0.6022446751594543, Diff of last 2: 8.893013000488281e-05]\n",
      "[Epoch: 3400, Error: 0.5862190127372742, Diff of last 2: 7.194280624389648e-05]\n",
      "[Epoch: 3600, Error: 0.5732782483100891, Diff of last 2: 5.829334259033203e-05]\n",
      "[Epoch: 3800, Error: 0.5628217458724976, Diff of last 2: 4.7206878662109375e-05]\n",
      "[Epoch: 4000, Error: 0.5543678998947144, Diff of last 2: 3.814697265625e-05]\n",
      "[Epoch: 4200, Error: 0.5475287437438965, Diff of last 2: 3.063678741455078e-05]\n",
      "[Epoch: 4400, Error: 0.5419933199882507, Diff of last 2: 2.5093555450439453e-05]\n",
      "[Epoch: 4600, Error: 0.5375111103057861, Diff of last 2: 2.0265579223632812e-05]\n",
      "[Epoch: 4800, Error: 0.5338800549507141, Diff of last 2: 1.627206802368164e-05]\n",
      "[Epoch: 5000, Error: 0.5309370756149292, Diff of last 2: 1.3232231140136719e-05]\n",
      "[Epoch: 5200, Error: 0.5285512208938599, Diff of last 2: 1.0669231414794922e-05]\n",
      "[Epoch: 5400, Error: 0.5266160368919373, Diff of last 2: 8.761882781982422e-06]\n",
      "[Epoch: 5600, Error: 0.5250464081764221, Diff of last 2: 6.854534149169922e-06]\n",
      "[Epoch: 5800, Error: 0.523772120475769, Diff of last 2: 5.9604644775390625e-06]\n",
      "[Epoch: 6000, Error: 0.5227380394935608, Diff of last 2: 4.649162292480469e-06]\n",
      "[Epoch: 6200, Error: 0.5218981504440308, Diff of last 2: 3.7550926208496094e-06]\n",
      "[Epoch: 6400, Error: 0.5212159752845764, Diff of last 2: 3.159046173095703e-06]\n",
      "[Epoch: 6600, Error: 0.5206618905067444, Diff of last 2: 2.562999725341797e-06]\n",
      "[Epoch: 6800, Error: 0.520211398601532, Diff of last 2: 2.1457672119140625e-06]\n",
      "[Epoch: 7000, Error: 0.519845724105835, Diff of last 2: 1.7881393432617188e-06]\n",
      "[Epoch: 7200, Error: 0.5195481777191162, Diff of last 2: 1.430511474609375e-06]\n",
      "[Epoch: 7400, Error: 0.5193065404891968, Diff of last 2: 9.5367431640625e-07]\n",
      "[Epoch: 7600, Error: 0.5191096067428589, Diff of last 2: 1.0728836059570312e-06]\n",
      "[Epoch: 7800, Error: 0.5189496278762817, Diff of last 2: 7.152557373046875e-07]\n",
      "MODEL: 4\n",
      "LR: 0.6\n",
      "RP: 0.001\n",
      "[Epoch: 0, Error: 4.450675010681152, Diff of last 2: 4995.549324989319]\n",
      "[Epoch: 200, Error: 2.760422468185425, Diff of last 2: 0.003686666488647461]\n",
      "[Epoch: 400, Error: 2.1652746200561523, Diff of last 2: 0.002422332763671875]\n",
      "[Epoch: 600, Error: 1.7558369636535645, Diff of last 2: 0.0017315149307250977]\n",
      "[Epoch: 800, Error: 1.4577910900115967, Diff of last 2: 0.001280069351196289]\n",
      "[Epoch: 1000, Error: 1.2356152534484863, Diff of last 2: 0.0009610652923583984]\n",
      "[Epoch: 1200, Error: 1.0680166482925415, Diff of last 2: 0.0007277727127075195]\n",
      "[Epoch: 1400, Error: 0.9407073259353638, Diff of last 2: 0.0005540847778320312]\n",
      "[Epoch: 1600, Error: 0.8435659408569336, Diff of last 2: 0.00042372941970825195]\n",
      "[Epoch: 1800, Error: 0.769202470779419, Diff of last 2: 0.0003247261047363281]\n"
     ]
    }
   ],
   "source": [
    "for model in range(NUMBER_OF_MODELS):\n",
    "    print('MODEL:', model)\n",
    "    LEARNING_RATE = LR_PARAMS[model]\n",
    "    REGULARIZATION_PARAM = REG_PARAMS[model]\n",
    "    \n",
    "    print('LR:', LEARNING_RATE)\n",
    "    print('RP:', REGULARIZATION_PARAM)\n",
    "    \n",
    "    #changing the parameters of model\n",
    "    cost = tf.reduce_mean(tf.reduce_mean(-tf.multiply(y, tf.log(hypotesis)) - \n",
    "                      tf.multiply(tf.subtract(1.0, y), tf.log(tf.subtract(1.0, hypotesis)))) \\\n",
    "                    + tf.multiply(REGULARIZATION_PARAM, tf.nn.l2_loss(Weights)))\n",
    "    \n",
    "    train_op = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(cost)\n",
    "    \n",
    "    W_computed, b_computed = train_with_parameters(TRAINING_EPOCHS, LEARNING_RATE, cost, train_op, X_train, y_train)\n",
    "    WEIGHTS_COMPUTED.append(W_computed)\n",
    "    BIASES_COMPUTED.append(b_computed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(WEIGHTS_COMPUTED)\n",
    "print(BIASES_COMPUTED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_with_params(W_computed, b_computed, X_validate, y_validate):\n",
    "    h = tf.sigmoid(b_computed + tf.matmul(X, W_computed))\n",
    "\n",
    "    cnt = 0\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        y_predict = sess.run(h, {X: X_validate})\n",
    "        y_predict_predict = []\n",
    "\n",
    "        for value in y_predict:\n",
    "            if np.mean(value) >= 0.5:\n",
    "                y_predict_predict.append(1)\n",
    "            else:\n",
    "                y_predict_predict.append(0)\n",
    "\n",
    "        y_diff = y_predict_predict == y_validate\n",
    "\n",
    "        for value in y_diff:\n",
    "            if value:\n",
    "                cnt += 1\n",
    "\n",
    "        print('Accuracy:', cnt/(len(y_diff)) * 100, '%')\n",
    "        return (cnt/len(y_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(WEIGHTS_COMPUTED)):\n",
    "    if WEIGHTS_COMPUTED[i] != np.inf:\n",
    "        ACCURACIES.append(validate_with_params(WEIGHTS_COMPUTED[i], BIASES_COMPUTED[i], X_validate, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCURACIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
